__license__ = "GPL v3"
__copyright__ = "2024, 0x6f677548 (Hugo Batista) <Ox6f677548 at outlook dot com>"
__docformat__ = "markdown en"

# this file is a common file to all IntelliReading metaguiding plugins.
# !!!! Do not edit this file out of common folder !!!!
# pylint: disable=import-error
import os
import sys
import time
from functools import partial
import traceback
from io import BytesIO
from os import path
import zipfile
import math
import re as re
from typing import Generator

from calibre import prints
from calibre.constants import (
    preferred_encoding,
)
from calibre.utils.logging import (
    ANSIStream,
)
from polyglot.builtins import is_py3
from polyglot.io import PolyglotStringIO

if is_py3:
    from typing import List


def metaguide_epub(input_path: str, output_path: str):
    """Converts an epub file to a metaguided epub file"""

    log.debug(f"Processing file '{input_path}' to output '{output_path}'")
    if not os.path.isfile(input_path):
        log.error(f"File {input_path} does not exist")
        raise ValueError(f"Input file '{input_path}' does not exist")

    file_extension = os.path.splitext(input_path)[-1].upper()
    if file_extension != ".EPUB":
        log.error(f"File {input_path} is not an epub")
        raise ValueError(f"Input file '{input_path}' is not an epub file")

    try:
        output = BytesIO()
        EpubTransformer().transform_file_to_stream(input_path, output)
        output.seek(0)
        with open(output_path, "wb") as output_file:
            output_file.write(output.read())
        log.debug(f"File {input_path} processed to {output_path}")
    except Exception as e:
        log.error(f"Error processing file '{input_path}'. Error: {e}")
        raise e


class Logger:
    LEVELS = {"DEBUG": 0, "INFO": 1, "WARN": 2, "ERROR": 3}

    def __init__(self) -> None:
        self.log_level = "INFO"
        if (
            "CALIBRE_DEVELOP_FROM" in os.environ
            or "CALIBRE_DEBUG" in os.environ
            or "calibre-debug" in sys.argv[0]
        ):
            self.log_level = "DEBUG"

        # According to Kovid, calibre always uses UTF-8 for the Python 3 version
        self.preferred_encoding = "UTF-8" if is_py3 else preferred_encoding
        self.outputs = [ANSIStream()]

        self.debug = partial(self.print_formatted_log, "DEBUG")
        self.info = partial(self.print_formatted_log, "INFO")
        self.warn = self.warning = partial(self.print_formatted_log, "WARN")
        self.error = partial(self.print_formatted_log, "ERROR")

    def __call__(self, logmsg) -> None:
        self.info(logmsg)

    def _tag_args(self, level, *args) -> List[str]:
        _now = time.localtime()
        _buf = PolyglotStringIO()
        _tagged_args = []
        for _arg in args:
            prints(time.strftime("%Y-%m-%d %H:%M:%S", _now), file=_buf, end=" ")
            _buf.write("[")
            prints(level, file=_buf, end="")
            _buf.write("] ")
            prints(_arg, file=_buf, end="")

            _tagged_args.append(_buf.getvalue())
            _buf.truncate(0)

        return _tagged_args

    def _prints(self, level: str, *args, **kwargs) -> None:
        for _o in self.outputs:
            _o.prints(self.LEVELS[level], *args, **kwargs)
            if hasattr(_o, "flush"):
                _o.flush()

    def print_formatted_log(self, level: str, *args, **kwargs) -> None:
        _tagged_args = self._tag_args(level, *args)
        self._prints(level, *_tagged_args, **kwargs)

    def exception(self, *args, **kwargs) -> None:
        _limit = kwargs.pop("limit", None)
        _tagged_args = self._tag_args("ERROR", *args)
        self._prints("ERROR", *_tagged_args, **kwargs)
        self._prints("ERROR", traceback.format_exc(_limit))


log = Logger()


class RegExBoldMetaguider:
    _body_regex = re.compile(r"<body[^>]*>(.*)</body>", re.DOTALL)
    _text_block_regex = re.compile(r"(?<!<b)>[^\S]*[^\s<][^<]*[^\S\n]*<")
    _word_pattern_regex = re.compile(r"\b\w+\b", re.UNICODE)
    _entity_ref_regex = re.compile(r"(&[#a-zA-Z][a-zA-Z0-9]*;)")

    def __init__(
        self, use_lxml_as_main_encoding_detector=False, fallback_encoding="utf-8"
    ) -> None:
        self._use_lxml_as_encoding_detector = use_lxml_as_main_encoding_detector
        self._fallback_encoding = fallback_encoding

    def _bold_word(self, word: str) -> str:
        # this is the function that is called for each word

        # if the word is an empty string, whitespace or new line, return it
        if not word.strip():
            return word

        length = len(word)
        midpoint = 1 if length == 1 or length == 3 else math.ceil(len(word) / 2)
        return f"<b>{word[:midpoint]}</b>{word[midpoint:]}"  # Bold the first half of the word

    def _bold_node_text_part(self, part: str) -> str:
        # is this part an entity reference?
        if self._entity_ref_regex.match(part):
            return part
        return self._word_pattern_regex.sub(lambda m: self._bold_word(m.group()), part)

    def _bold_text_node(self, node: str) -> str:
        # this is the function that is called for each text node
        node_text = node[1:-1]

        # split the node_text into parts based on the entity references
        node_text_parts = self._entity_ref_regex.split(node_text)

        new_node_text = "".join(map(self._bold_node_text_part, node_text_parts))

        if node_text != new_node_text:
            return ">" + new_node_text + "<"
        return node

    def _bold_document(self, html: str) -> str:
        # get the body. If there is no body, return the original html
        match = self._body_regex.search(html)
        if match:
            body = match.group(1)
        else:
            return html

        # find all text nodes in the body and trigger the bolding of the words
        body = self._text_block_regex.sub(
            lambda m: self._bold_text_node(m.group()), body
        )

        html = html.replace(match.group(1), body)
        return html

    def _get_encoding_using_lxml(self, xhtml_document: bytes) -> str | None:
        from lxml import etree

        parser = etree.XMLParser(resolve_entities=False)
        doc = etree.fromstring(xhtml_document, parser=parser).getroottree()
        docinfo = doc.docinfo
        return docinfo.encoding

    def _get_encoding_using_bom(self, xhtml_document: bytes) -> str | None:
        if xhtml_document.startswith(b"\xef\xbb\xbf"):
            return "utf-8"
        elif xhtml_document.startswith(b"\xff\xfe"):
            return "utf-16-le"
        elif xhtml_document.startswith(b"\xfe\xff"):
            return "utf-16-be"
        elif xhtml_document.startswith(b"\x00\x00\xfe\xff"):
            return "utf-32-be"
        elif xhtml_document.startswith(b"\xff\xfe\x00\x00"):
            return "utf-32-le"
        else:
            return None

    def _get_encoding_using_xml_header(self, xhtml_document: bytes) -> str | None:
        # if the document does not start with an XML header, return None. This is not a xml document
        if not xhtml_document.startswith(b"<?xml "):
            return None

        xml_header_end = xhtml_document.find(b"?>") + 1
        if xml_header_end == 0:
            raise ValueError(
                "Invalid XHTML document. Could not find closing XML element."
            )

        header = xhtml_document[:xml_header_end].decode("utf-8")
        match = re.search(
            r'encoding=(["\'])([a-zA-Z][a-zA-Z0-9-]{0,38}[a-zA-Z0-9])\1', header
        )
        if match:
            return match.group(2)
        else:
            # although the XML header is present, it does not contain an encoding
            # this is not a valid XHTML document, but we can still try to detect the encoding on a later stage
            # and we will not raise an exception
            return None

    def _get_encoding(self, xhtml_document: bytes) -> str:
        encoding = None
        if self._use_lxml_as_encoding_detector:
            encoding = self._get_encoding_using_lxml(xhtml_document)

        if not encoding:
            encoding = self._get_encoding_using_xml_header(xhtml_document)

        if not encoding:
            encoding = self._get_encoding_using_bom(xhtml_document)

        if not encoding and not self._use_lxml_as_encoding_detector:
            log.warn(
                "Could not detect the encoding of the XHTML document. Trying to detect the encoding using lxml."
            )
            encoding = self._get_encoding_using_lxml(xhtml_document)

        return encoding or self._fallback_encoding

    def metaguide_xhtml_document(self, xhtml_document: bytes) -> bytes:
        # if none of the methods to detect the encoding work, use utf-8
        encoding = self._get_encoding(xhtml_document) or "utf-8"

        html = xhtml_document.decode(encoding)
        bolded_html = self._bold_document(html)
        return bolded_html.encode(encoding)


class EpubItemFile:
    def __init__(self, filename: str | None = None, content: bytes = b"") -> None:
        self.filename = filename
        self.content = content
        file_extension = (
            self.filename and path.splitext(self.filename)[-1].upper() or None
        )

        # some epub have files with html extension but they are xml files
        self.is_xhtml_document = (
            file_extension == ".HTM"
            or file_extension == ".HTML"
            or file_extension == ".XHTML"
            or file_extension == ".XML"
        )
        self.transformed = False

    def __str__(self) -> str:
        return f"{self.filename} ({len(self.content)} bytes)"

    def transform(self, metaguider: RegExBoldMetaguider) -> "EpubItemFile":
        if self.transformed:
            log.warning(f"File {self.filename} already transformed, skipping")
        elif self.is_xhtml_document:
            log.debug(f"transform (begin): {self.filename}")
            self.content = metaguider.metaguide_xhtml_document(self.content)
            self.transformed = True
            log.debug(f"transform (end): {self.filename}")
        else:
            log.debug(f"Skipping file '{self.filename}' because it is not a xhtml file")
        return self


class EpubTransformer:
    def __init__(
        self,
        metaguider=RegExBoldMetaguider(),
    ) -> None:
        self._metaguider = metaguider

    def _get_epub_item_files_from_zip(self, input_zip: zipfile.ZipFile) -> list:
        def _read_compressed_file(
            input_zip: zipfile.ZipFile, filename: str
        ) -> EpubItemFile:
            return EpubItemFile(filename, input_zip.read(filename))

        _epub_item_files = list(
            map(
                lambda f: _read_compressed_file(input_zip, f.filename),
                input_zip.infolist(),
            )
        )
        return _epub_item_files

    def _process_epub_item_files(
        self, epub_item_files: list[EpubItemFile]
    ) -> Generator[EpubItemFile, None, None]:
        for _epub_item_file in epub_item_files:
            log.debug(f"Processing file '{_epub_item_file.filename}'")
            yield _epub_item_file.transform(self._metaguider)

    def _write_item_files_to_zip(self, epub_item_files, output_zip):
        def _write_compressed_file(
            output_zip: zipfile.ZipFile, epub_item_file: EpubItemFile
        ):
            if epub_item_file.filename is None:
                raise ValueError("EpubItemFile.filename is None")

            log.debug(f"Writing file '{epub_item_file.filename}' to output zip")
            with output_zip.open(
                epub_item_file.filename, mode="w"
            ) as _compressed_output_file:
                _compressed_output_file.write(epub_item_file.content)

        for _epub_item_file in epub_item_files:
            _write_compressed_file(output_zip, _epub_item_file)

    def _process_zip(self, input_zip: zipfile.ZipFile, output_zip: zipfile.ZipFile):
        log.debug("Processing zip: Getting item files")
        epub_item_files = self._get_epub_item_files_from_zip(input_zip)
        processed_item_files = self._process_epub_item_files(epub_item_files)
        log.debug("Processing zip: Writing output zip")
        self._write_item_files_to_zip(processed_item_files, output_zip)

    def transform_file_to_stream(self, input_file_name, output_stream: BytesIO):
        log.debug(f"Transforming input file {input_file_name} to output stream")
        with zipfile.ZipFile(
            input_file_name, "r", compression=zipfile.ZIP_DEFLATED, allowZip64=True
        ) as _input_zip:
            with zipfile.ZipFile(
                output_stream, "w", compression=zipfile.ZIP_DEFLATED, allowZip64=True
            ) as _output_zip:
                self._process_zip(_input_zip, _output_zip)
